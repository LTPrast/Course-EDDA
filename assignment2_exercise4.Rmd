---
title: "Assignment 1"
author: 'Group 67: Jamie Faber, Laurens Prast, Amal Salman'
date: "27 February 2022"
output:
  html_document:
    df_print: paged
  pdf_document: default
highlight: tango
---
```{r include = FALSE}
options(digits=3)
options(knitr.duplicate.label = "allow")
```

## Imports
```{r}
library(ggplot2)
library(car)
library(tidyverse)
library(broom)

```

## Exercise 4
### a) 
```{r}
psidata=read.table(file="psi.txt",header=TRUE)
psidata
```

```{r}
psi_model <- glm(passed~gpa+psi, data = psidata, family = binomial)
psi_model2 <- glm(passed~gpa, data = psidata, family = binomial)
anova(psi_model2,psi_model,test="Chisq")
```
p-value < 0.05 and so there is significant dependence between psi and passed. So psi works.

Checking assumptions:
```{r}
model <- glm(passed~., data = psidata, family = binomial)
probabilities <- predict(model, type = "response")

# Select only numeric predictors
mydata <- psidata %>%
  dplyr::select_if(is.numeric) 

predictors <- colnames(mydata)
# Bind the logit and tidying the data for plot
mydata <- mydata %>%
  mutate(logit = log(probabilities/(1-probabilities))) %>%
  gather(key = "predictors", value = "predictor.value", -logit)

ggplot(mydata, aes(logit, predictor.value))+
  geom_point(size = 0.5, alpha = 0.5) +
  geom_smooth(method = "loess") + 
  theme_bw() + 
  facet_wrap(~predictors, scales = "free_y")
```
(second plot shouldn't be included)

We can see that there is a linear relationship between continuous predictor variables (gpa) and the logit of the outcome (passed). Therefore, this assumption is met.

```{r}
model.data <- augment(model) %>% 
  mutate(index = 1:n()) 
# augment() computes the standardized residuals and the Cook’s distance

model.data %>% 
  filter(abs(.std.resid) > 3)
# filters potential influential data points 
```
There is no influential values (outliers) in the continuous predictors

```{r}
car::vif(model)
```
Both values are less than 5, so there is no high intercorrelations (i.e. multicollinearity) among the predictors.

Therefore all assumptions for the logistic regression are met.

### b)

```{r}
psidata$gpa=factor(psidata$gpa); psidata$psi=factor(psidata$psi)
psi_model2 <- glm(passed~psi+gpa, data = psidata, family = binomial)
summary(psi_model2)
```

```{r}
 predict(psi_model2,data.frame(psi="1",gpa="3.03"),type="response")

 predict(psi_model2,data.frame(psi="0",gpa="3.03"),type="response")
```

Estimated probability that student passes with gpa=3 and receives psi
= 1

Estimated probability that student passes with gpa=3 and doesn't receive psi
= 2.9e-12 

Comment: a student with 3.03 gpa who receives psi will almost certainly pass while the one who doesn't will almost certainly fail.

### c)

```{r}
psi_model3 = glm(passed~psi, data = psidata, family = binomial)
predict(psi_model3,data.frame(psi="0"),type="response")
predict(psi_model3,data.frame(psi="1"),type="response")
```
relative change in odds = 0.571/0.167 = 3.42
OR
relative change in odds = exp(4.98e+01 + 7.63e+01) = 5.81e+54
?

Interpretation: 
Students receiving psi rather than not would increase their odds of passing by a factor of 5.81e+54 

```{r}
psi_interaction=glm(passed~gpa*psi,data=psidata,family=binomial)
anova(psi_interaction,test="Chisq")
```
p-value=1 > 0.05 so there is no interaction between receiving psi and age, 
so the odds estimated above is not dependent on gpa.

### d)

```{r}
matrix=xtabs(~passed+psi,data=psidata)
matrix
```

```{r}
chisq.test(matrix,simulate.p.value=TRUE)
```
p-value < 0.05 so psi and passed are dependent of one another.

Since our table is 2x2, we can use Fisher’s test to compute an exact p-value:
```{r}
fisher.test(matrix)
```
Same p-value as the chisquare approximation.

Therefore came at the same conclusion from the first analysis (part a)

In the contingency table analysis, all of the counts are >1 and 1 count (25% of the counts) is less than 5 (when no more than 20% should be <5), making this approximation by the chi-square test not reliable.


### e)

All assumptions for the logistic regression are met, unlike the assumptions for the contingency table analysis. In logistic regression we were able to include gpa in the analysis but not in the contingency table. Since we're primarily interested in whether psi works (not in predicting how well it works in certain cases) then contingency table analysis is more appropriate/relevant.



