---
title: "Assignment 1"
author: 'Group 67: Jamie Faber, Laurens Prast, Amal Salman'
date: "27 February 2022"
output:
  html_document:
    df_print: paged
  pdf_document: default
highlight: tango
---
```{r include = FALSE}
options(digits=3)
options(knitr.duplicate.label = "allow")
```

## Imports
```{r}
library(ggplot2)
library(car)
library(tidyverse)
library(broom)

```

## Exercise 4
### a) 
```{r}
psidata=read.table(file="psi.txt",header=TRUE)
psidata
```

```{r}
psi_model <- glm(passed~gpa+psi, data = psidata, family = binomial)
psi_model2 <- glm(passed~gpa, data = psidata, family = binomial)
anova(psi_model2,psi_model,test="Chisq")
```
p-value > 0.05 and so is not significant. No evidence that psi  works.

### b)

```{r}
psidata$gpa <- round(psidata$gpa ,digit=1)
psidata$gpa=factor(psidata$gpa); psidata$psi=factor(psidata$psi)
psi_model2 <- glm(passed~gpa+psi, data = psidata, family = binomial)
summary(psi_model2)
```
round gpa?

Estimated probability that student passes with gpa=3 and receives psi
= exp(41.5 + 41.5) = exp(83) = 1.11e+36 ?

Estimated probability that student passes with gpa=3 and doesn't receive psi
= exp(41.5 - 64.1) = exp(-22.6) = 1.53e-10

Comment?

```{r}
41.5 - 64.1
exp(41.5 - 64.1)
```


### c)

relative change in odds of passing with psi rather than without
= exp(49.8 + 76.3) = 5.81e+54 (correct?)

Interpretation: 
Students receiving psi rather than not would increase their odds of passing by a factor of 5.81e+54 

```{r}
psi_interaction=glm(passed~gpa*psi,data=psidata,family=binomial)
anova(psi_interaction,test="Chisq")
```
p-value=1 > 0.05 so there is no interaction between receiving psi and age, 
so the odds estimated above is not dependent on gpa.

### d)

```{r}
psidata$gpa <- as.numeric(as.character(psidata$gpa))

matrix=xtabs(~gpa+psi,data=psidata)
matrix
```

```{r}
chisq.test(matrix,simulate.p.value=TRUE)
```
p-value > 0.05 so gpa and psi are independent of one another.

Therefore came at the same conclusion as the first analysis (checking interaction with anova)

### e)

In the contingency table analysis, many of the counts are 0 (not >1) and 100% of the counts are less than 5 (when no more than 20% should be <5), making this approximation by the
chi-square test not reliable.

```{r}
model <- glm(passed~., data = psidata, family = binomial)
probabilities <- predict(model, type = "response")

# Select only numeric predictors
mydata <- psidata %>%
  dplyr::select_if(is.numeric) 

predictors <- colnames(mydata)
# Bind the logit and tidying the data for plot
mydata <- mydata %>%
  mutate(logit = log(probabilities/(1-probabilities))) %>%
  gather(key = "predictors", value = "predictor.value", -logit)

ggplot(mydata, aes(logit, predictor.value))+
  geom_point(size = 0.5, alpha = 0.5) +
  geom_smooth(method = "loess") + 
  theme_bw() + 
  facet_wrap(~predictors, scales = "free_y")
```
(passed shouldn't be included)

We can see that there is a linear relationship between continuous predictor variables (gpa) and the logit of the outcome (passed). Therefore, this assumption is met.

```{r}
model.data <- augment(model) %>% 
  mutate(index = 1:n()) 
# augment() computes the standardized residuals and the Cookâ€™s distance

model.data %>% 
  filter(abs(.std.resid) > 3)
# filters potential influential data points 
```
There is no influential values (outliers) in the continuous predictors

```{r}
car::vif(model)
```
Both values are less than 5, so there is no high intercorrelations (i.e. multicollinearity) among the predictors.



Therefore all assumptions for the logistic regression are met, unlike the assumptions for the contingency table analysis. On the other hand, the contingency table analysis directly tests the dependence between two factors, while the logistic regression only tests whether there is interaction between them.



